from nltk.tokenize import WordPunctTokenizer

# Tokenizing a text
tokens = WordPunctTokenizer().tokenize('Just a simple text.')
print(tokens)