{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM93YbeZ4t5DDN/ijNOaKct",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/NaturalLanguageProcessingBasics/blob/main/NextWordPredictionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras.layers.core"
      ],
      "metadata": {
        "id": "QcUtLw-4J85j",
        "outputId": "5055acc1-5831-4135-a9d0-1bdf9e2e70fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement keras.layers.core (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for keras.layers.core\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5mAgW_vFHJiu"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary libraries:\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM\n",
        "#from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset:\n",
        "path = '1661-0.txt'\n",
        "text = open(path).read().lower()\n",
        "print('corpus length:', len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXLXRTRfJNl2",
        "outputId": "a22406ed-cc87-4899-d56b-86dd8dcb503b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 581888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into each word in order but without the presence\n",
        "# of some special characters:\n",
        "tokenizer = RegexpTokenizer(r'w+')\n",
        "words = tokenizer.tokenize(text)"
      ],
      "metadata": {
        "id": "o-ozNWOcJwbm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Requiring a dictionary with each word in the data within the list\n",
        "# of unique words as the key, and its significant portions as values:\n",
        "unique_words = np.unique(words)\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
      ],
      "metadata": {
        "id": "fTabnqCZKH_j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Word length which will represent the number of previous words that\n",
        "# will determine our next word.\n",
        "WORD_LENGTH = 5\n",
        "previous_words = []\n",
        "next_words = []\n",
        "for i in range(len(words) - WORD_LENGTH):\n",
        "  previous_words.append(words[i : i + WORD_LENGTH])\n",
        "  next_words.append(words[i + WORD_LENGTH])\n",
        "print(previous_words[0])\n",
        "print(next_words[0])"
      ],
      "metadata": {
        "id": "5RZx-g4ELerG",
        "outputId": "ba155f5a-2fe0-4ba3-b014-67b1fd7358a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['w', 'w', 'w', 'w', 'w']\n",
            "www\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating numpy arrays x for storing the features and y for\n",
        "# storing its corresponding label.\n",
        "X = np.zeros((len(previous_words), WORD_LENGTH, len(unique_words)), dtype = bool)\n",
        "Y = np.zeros((len(next_words), len(unique_words)), dtype = bool)\n",
        "for i, each_words in enumerate(previous_words):\n",
        "  for j, each_word in enumerate(each_words):\n",
        "    X[i, j, unique_word_index[each_word]] = 1\n",
        "    Y[i, unique_word_index[next_words[i]]] = 1"
      ],
      "metadata": {
        "id": "CXOYCza_LOoM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the sequence of words:\n",
        "print(X[0][0])"
      ],
      "metadata": {
        "id": "1HLgFFDVMdXx",
        "outputId": "2ff0b8fb-efa2-4066-82ed-4ebf1743a888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the LSTM model, which is a Recurrent Neural networks for\n",
        "# next word prediction model:\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape = (WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "TfNefMs7MokT",
        "outputId": "7a1a881c-5348-4c55-9ff2-ab7ebd929832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-42ea4e40728d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mWORD_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dense' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the word prediction with 20 epochs:\n",
        "optimizer = RMSprop(lr = 0.01)\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = optimizer,\n",
        "              metrics = ['accuracy'])\n",
        "history = model.fit(X,\n",
        "                    Y,\n",
        "                    validation_split = 0.05,\n",
        "                    batch_size = 128,\n",
        "                    epochs = 2,\n",
        "                    shuffle = True).history"
      ],
      "metadata": {
        "id": "zsCFqJAgQhTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model for future use:\n",
        "model.save('keras_next_word_model.h5')\n",
        "pickle.dump(history, open('history.p', 'wb'))\n",
        "model = load_model('keras_next_word_model.h5')\n",
        "history = picke.load(open('history.p', 'rb'))"
      ],
      "metadata": {
        "id": "Oc6Mwihie1c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model based on how its accuracy changes while training:\n",
        "plt.plot(history['acc'])\n",
        "plt.plot(history['val_acc'])\n",
        "plt.title('model_accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')"
      ],
      "metadata": {
        "id": "QSIFNCilpaws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model based on how its loss changes while training:\n",
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')"
      ],
      "metadata": {
        "id": "VDtaAB7-qKBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a program to predict th next word using the training model:\n",
        "def prepare_input(text):\n",
        "  x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
        "  for t, char in enumerate(text):\n",
        "    x[o, t, char_indexes[char]] = 1.\n",
        "  return x"
      ],
      "metadata": {
        "id": "nYO8sfkoqCJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the fnction (making sure to use a lower() function while giving input )\n",
        "prepare_input('This is an example of input'.lower())"
      ],
      "metadata": {
        "id": "xY9w908bvEAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if the created function is working:\n",
        "def prepare_input(text):\n",
        "  x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
        "  for t, word in enumerate(text.split()):\n",
        "    print(word)\n",
        "    x[0, t, unique_word_index[word]] = 1\n",
        "  return x\n",
        "prepare_input('It is not a lack'.lower())"
      ],
      "metadata": {
        "id": "CqbhpT8PviVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to return samples:\n",
        "def sample(preds, top_n = 3):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds)\n",
        "  exp_preds = np.expp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "  return heapq.nlargest(top_n, range(len(preds), preds.take)"
      ],
      "metadata": {
        "id": "no8d_6_NwVPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_completion(text):\n",
        "  original_text = text\n",
        "  generated = text\n",
        "  generated = text\n",
        "  compeltion = ''\n",
        "  while True:\n",
        "    X = prepare_input(text)\n",
        "    preds = model.predict(X, verbose = 0)[0]\n",
        "    next_index = sample(preds. top_n = 1)[0]\n",
        "    next_char = indexes_char[next_index]\n",
        "    text = text[1:] + next_char\n",
        "    completion += next_char\n",
        "\n",
        "    if len(original_text + completion) + 2 > len(original_text)\n",
        "    and next_char == ' ':\n",
        "      return completion"
      ],
      "metadata": {
        "id": "zwPVG_VYxk57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the next word until space is generated by iterating the input,\n",
        "# which will ask the RNN model and extracts instances from it:\n",
        "def predict_completions(text, n = 3):\n",
        "  x = prepare-input(text)\n",
        "  preds = model.predict(x, verbose = 0)[0]\n",
        "  next_indexes = sample(preds, n)\n",
        "  return [indexes_char,[idx] + predict_completion(text[1:] + indexes_char[idx])\n",
        "  for idx in next_indexes]"
      ],
      "metadata": {
        "id": "xdlCL2HMlsnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a sequence of 40 characters that can be used as a base for\n",
        "# the predictions:\n",
        "quotes = [\n",
        "    'It is not a lack of love, but a lack of friendship that makes unhappy marriages.,\n",
        "    'That which does not kill us makes us stronger.',\n",
        "    'I am not upset that you lied to me, I am upset that from now on I cannot believe you.',\n",
        "    'And those who were seen dancing were thought to be insane by those who could not hear the music.',\n",
        "    'It is hard enough to remember my opinions, without also remembering my reasons for them!'\n",
        "]"
      ],
      "metadata": {
        "id": "TpLPYq8amseW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the model to predict the next word:\n",
        "for q in quotes:\n",
        "  seq = q[:40].lower()\n",
        "  print(seq)\n",
        "  print(predict_completions(seq, 5))\n",
        "  print()"
      ],
      "metadata": {
        "id": "AViiF-U7nKtM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}